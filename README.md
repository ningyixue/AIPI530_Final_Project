# AIPI 530 Final Project - Ningyi Xue


This repo is for AIPI 530 final project, and the goal of this project is to build a pipeline for offline reinforcement learning on top of [d3rlpy](https://github.com/takuseno/d3rlpy)

## Preface - Reinforcement Learning
Please check out this [blog]() post for basic understanding of reinforcement learning. The following information is included in the blog post:
- What is reinforcement learning?
- What are the pros and cons of reinforcement learning?
- When should we consider applying reinforcement learning (and when should not)?
- What's the difference between supervised learning and reinforcement learning?
- What is offline reinforcement learning?
- What are the pros and cons of offline reinforcement learning?
- When should we consider applying offline reinforcement learning (and when should not)?
- An example of offline reinforcement learning in the real-world.


## Installation
### Please follow the below steps for installation:
### Step 1:
Git clone this repository:
- !git clone https://github.com/ningyixue/AIPI530_Final_Project.git
### Step 2:
Install packages if you don't have:
- !pip install Cython numpy
- !pip install -e
### Step 3:
Install pybullet:
- !pip install git+https://github.com/takuseno/d4rl-pybullet

## Execution



## citation
The paper is available [here](https://arxiv.org/abs/2111.03788).
```
@InProceedings{seno2021d3rlpy,
  author = {Takuma Seno, Michita Imai},
  title = {d3rlpy: An Offline Deep Reinforcement Library},
  booktitle = {NeurIPS 2021 Offline Reinforcement Learning Workshop},
  month = {December},
  year = {2021}
}
```
